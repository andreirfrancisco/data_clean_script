{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e639c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "folder = \"update_weekly\"\n",
    "def collect_files(folder, pattern):\n",
    "    dictionary = {}\n",
    "    for second_folder in os.listdir(folder):\n",
    "    # folder\n",
    "    # files had date in format MM/DD/YY\n",
    "        if '12_18_24' not in second_folder and  '12_25_24' not in second_folder:\n",
    "            second_path = os.path.join(folder, second_folder)\n",
    "            # folder also other files that are not part of the datasets\n",
    "            if '.py' not in second_path and '.ipynb' not in second_path and \"MERGED_\" not in second_path:\n",
    "                for file in os.listdir(second_path):\n",
    "                    if pattern in file.lower() and \"merged_\" not in file.lower():\n",
    "                        date = second_folder.replace(\"_Report\", \"\")\n",
    "                        date = date.replace(\"_\", \"/\")\n",
    "                        date = date + \"/\" + \"2025\"\n",
    "                        # print(date)\n",
    "                        dictionary[date] = os.path.join(second_folder,file)\n",
    "    return dictionary\n",
    "\n",
    "# Merging for all files\n",
    "def merge(folder):\n",
    "    ''''\n",
    "    handles datasets and put into 1 file.\n",
    "    '''\n",
    "    # gather all files into dataframe\n",
    "    data_frames = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \"_DATA.xlsx\" not in file:\n",
    "            df = pd.read_excel(os.path.join(folder, file))\n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            post_columns = df.columns\n",
    "            data_frames.append(df)\n",
    "    # the dataset concat from all files\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)  # Use ignore_index=True to reset the index\n",
    "    # final name of the file\n",
    "    path = (os.path.basename(folder) + \"_DATA.xlsx\")\n",
    "    path = os.path.join(folder, path)\n",
    "    print(path)\n",
    "    # load file into folder\n",
    "    merged_df.to_excel(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to see all files\n",
    "common_pattern ='Report'\n",
    "reports = []\n",
    "folder = \"update_weekly\"\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(common_pattern):\n",
    "        reports.append(file)\n",
    "for report in reports : \n",
    "    # find the index\n",
    "    rep_index = report.find(common_pattern)\n",
    "    date= report[0:rep_index]\n",
    "    if report.endswith(\"24_\") == False and '2025' not in report and '2024' not:\n",
    "       new_file_name = (date + \"2025\" + \"_Report\")\n",
    "       os.rename(report, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ae09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another method for collecting files\n",
    "def collect_files(folder, pattern):\n",
    "    file_dictionary = {}\n",
    "    # list all folders\n",
    "    for file in os.listdir(folder):\n",
    "\n",
    "        if file.endswith('Report'):\n",
    "            report_path = os.path.join(folder, file)\n",
    "\n",
    "            rep_index = file.find(pattern)\n",
    "            key= file[0:(rep_index-(len('Report')))]\n",
    "            key = key.replace(\"_\", \"/\")\n",
    "                # filter by Pattern\n",
    "            for file_2 in os.listdir(report_path):\n",
    "                if pattern.lower() in file_2.lower():\n",
    "                    value = file_2\n",
    "                    # file_2 path \n",
    "                    file_2_path = os.path.join(report_path, file_2)\n",
    "                    value = file_2_path\n",
    "                        \n",
    "                    file_dictionary[key] = value\n",
    "    return file_dictionary\n",
    "# method to create dataset for each sheet\n",
    "\n",
    "def sheet_dataset(folder):\n",
    "    # takes the folder and insert file as FOLDER_dataset.xlsx\n",
    "    dfs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \"_dataset.xlsx\" not in file:\n",
    "            df = pd.read_excel(os.path.join(folder, file), index_col=0)\n",
    "            dfs.append(df)\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)  # Use ignore_index=True to reset the index\n",
    "    path = (os.path.basename(folder) + \"_dataset.xlsx\")\n",
    "    path = os.path.join(folder, path)\n",
    "    return merged_df\n",


    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9856917",
   "metadata": {},
   "source": [
    "# 1. Arrival Separations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ee2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sheet create \n",
    "def Arrivals(file, date):\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name = \"Arrivals\")\n",
    "    # add week \n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    df['week'] = date\n",
    "    date = date.replace(\"/\", \"_\")\n",
    "    sheet_name = date + \"_for_arrivals_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"ARRIVALS\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Separations(file , date):\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name = \"Separations\")\n",
    "    # add week \n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    df['week'] = date\n",
    "    date = date.replace(\"/\", \"_\")\n",
    "    print(date)\n",
    "    sheet_name = date + \"_for_separations_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"SEPARATIONS\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Ordinary_Separations(file , date):\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name=\"Ordinary Separations\")\n",
    "        # Add your code that manipulates the DataFrame here\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    df['week'] = date\n",
    "    date = date.replace(\"/\", \"_\")\n",
    "    sheet_name = date + \"_for_ordinary_separations_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"ORDINARY_SEPARATIONS\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "def Resignations(file , date):\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name=\"Resignations\")\n",
    "        # Add your code that manipulates the DataFrame here\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    df['week'] = date\n",
    "    date = date.replace(\"/\", \"_\")\n",
    "    sheet_name = date + \"_for_resignations_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"RESIGNATIONS\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e850334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'arrivals_separations'\n",
    "arrival_files= collect_files(folder = folder, pattern = pattern)\n",
    "\n",
    "# for date , file  in arrival_files.items():\n",
    "#     Arrivals(file, date)\n",
    "#     Separations(file, date)\n",
    "#     Ordinary_Separations(file, date)\n",
    "#     Resignations(file, date)\n",
    "\n",
    "arr_sheet = sheet_dataset(\"ARRIVALS\")\n",
    "sep_sheet = sheet_dataset(\"SEPARATIONS\")\n",
    "ors_sheet = sheet_dataset(\"ORDINARY_SEPARATIONS\")\n",
    "res_sheet = sheet_dataset(\"RESIGNATIONS\")\n",
    "\n",
    "with pd.ExcelWriter('arrivals_separations_dataset.xlsx', engine='openpyxl') as writer:\n",
    "    arr_sheet.to_excel(writer, sheet_name='Arrivals', index=False)  # Save df to Sheet1\n",
    "    sep_sheet.to_excel(writer, sheet_name='Separations', index=False)  # Save df_2 to Sheet2\n",
    "    ors_sheet.to_excel(writer, sheet_name='Ordinary Separations', index=False)  # Save df to Sheet1\n",
    "    res_sheet.to_excel(writer, sheet_name='Resignations', index=False)  # Save df_2 to Sheet2\n",
    "\n",
    "sheets = pd.ExcelFile('arrivals_separations_dataset.xlsx').sheet_names\n",
    "\n",
    "sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19b55f",
   "metadata": {},
   "source": [
    "# 2. Clothing Allowance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for cleaning and transforming data\n",
    "def Region_Summary(file,date):\n",
    "    sheet_name = 'Region Summary'\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name =sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    # remove the first column\n",
    "    df = df[1:]\n",
    "    df.columns = df.iloc[0]\n",
    "    # then remove the first row \n",
    "    df = df[1:]\n",
    "    df.columns\n",
    "    # rename columns\n",
    "    df = df.rename(columns = {df.columns[1]: \"Issue Amount\"})\n",
    "    df = df.rename(columns = {df.columns[2]: \"Spent Amount\"})\n",
    "    # add column\n",
    "    df['week'] = date\n",
    "    week = date.replace(\"/\", \"_\")\n",
    "    sheet_name = week + \"_for_region_summary_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"CLOTHING_REGION_SUMMARY\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Region_Center_Summary(file, date):\n",
    "    sheet_name = \"Region Center Summary\"\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    \n",
    "    # use first row as columns\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df['week'] = date\n",
    "    week = date.replace(\"/\", \"_\")\n",
    "    sheet_name = week + \"_for_region_center_summary_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"CLOTHING_REGION_CENTER_SUMMARY\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Clothing_PY(file, date):\n",
    "    sheet_name = 'PY to Date'\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    df = df[1:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df = df.rename(columns = {df.columns[1]: \"Issue Amount(PY)\"})\n",
    "    df = df.rename(columns = {df.columns[2]: \"Spent Amount(PY)\"})\n",
    "    df['week'] = date\n",
    "    week = date.replace(\"/\", \"_\")\n",
    "    sheet_name = week + \"_for_clothing_py_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"CLOTHING_PY_SUMMARY\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'clothing_allowance'\n",
    "clothing_files= collect_files(folder = folder, pattern = pattern)\n",
    "\n",
    "for date, file in clothing_files.items():\n",
    "    Region_Summary(file , date)\n",
    "    Region_Center_Summary(file, date)\n",
    "    Clothing_PY(file, date)\n",
    "\n",
    "\n",
    "clo_reg_sheet = sheet_dataset(\"CLOTHING_REGION_SUMMARY\")\n",
    "clo_reg_center_sheet = sheet_dataset(\"CLOTHING_REGION_CENTER_SUMMARY\")\n",
    "clo_py_sheet = sheet_dataset(\"CLOTHING_PY_SUMMARY\")\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('clothing_allowance_dataset.xlsx', engine='openpyxl') as writer:\n",
    "    clo_py_sheet.to_excel(writer, sheet_name=\"PY\", index = False)\n",
    "    clo_reg_center_sheet.to_excel(writer, sheet_name = \"Region and Center\", index= False)\n",
    "    clo_reg_sheet.to_excel(writer, sheet_name = \"Region\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48994151",
   "metadata": {},
   "source": [
    "# 3. Online Prospect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Online_prospect_week(file, date):\n",
    "    sheet_name = 'Week data'\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "        sheet_name = 'Week'\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "    if 'reg_name' in df.columns:\n",
    "        df = df.rename(columns={'reg_name': 'Region'})\n",
    "    df['week'] = date\n",
    "    week = date.replace(\"/\", \"_\")\n",
    "    sheet_name = week + \"_for_online_prospect_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"ONLINE_PROSPECT\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Online_prospect_py(file, date):\n",
    "    sheet_name = 'PY'\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {date}\")\n",
    "    df = df[2:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns={'index'})\n",
    "    df = df[1:]\n",
    "    if 'region' in df.columns:\n",
    "        df = df.rename(columns={'region': 'Region'})\n",
    "    application_types = list(df.columns)\n",
    "    application_types = application_types.remove('Region')\n",
    "    # unpivot the tbale\n",
    "    df = df.melt(id_vars= 'Region', value_vars= application_types , var_name = \"Application Type\",  value_name='Count')\n",
    "    df = df.sort_values(by = 'Region')\n",
    "    df['week'] = date\n",
    "    week = date.replace(\"/\", \"_\")\n",
    "    sheet_name = week + \"_for_online_prospect_py_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"ONLINE_PROSPECT_PY\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'onlineprospect'\n",
    "online_prospect_files= collect_files(folder = folder, pattern = pattern)\n",
    "online_prospect_files\n",
    "for date, file in online_prospect_files.items():\n",
    "    Online_prospect_py(file , date)\n",
    "    Online_prospect_week(file, date)\n",
    "\n",
    "\n",
    "online_py_sheet = sheet_dataset(\"ONLINE_PROSPECT_PY\")\n",
    "online_prospect_sheet = sheet_dataset(\"ONLINE_PROSPECT\")\n",
    "\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('online_prospect_dataset.xlsx', engine='openpyxl') as writer:\n",
    "    online_py_sheet.to_excel(writer, sheet_name=\"Online Prospect PY\", index = False)\n",
    "    online_prospect_sheet.to_excel(writer, sheet_name = \"Online Prospect\", index= False)\n",
    "df = pd.read_excel('online_prospect_dataset.xlsx', index_col=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244101bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad71d8b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "611eafbc",
   "metadata": {},
   "source": [
    "# 4. PFD PDOF UA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b40107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries for file\n",
    "from datetime import date, datetime, timedelta\n",
    "# methods for cleaning and transforming\n",
    "def PFD(week, file):\n",
    "    sheet_name = 'PFD'\n",
    "    # issue is that columns are string need to be in MM-DD-YYYY format\n",
    "    string_with_dates = {}\n",
    "    day_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    try :\n",
    "        df = pd.read_excel(file , sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    # luckly the first column has start date and end date to convert string to numeric\n",
    "    date_range = df.columns[0]\n",
    "    index_string = date_range.index('between')\n",
    "    # the seperator is the between so lets get the dates\n",
    "    index_string =date_range[(index_string+len('between')):]\n",
    "    index_string = index_string.strip().replace(' ', '')\n",
    "    dates = index_string.split('and',1)\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime.strptime(dates[0], '%m/%d/%Y')\n",
    "    end_date = datetime.strptime(dates[1], '%m/%d/%Y')\n",
    "    # Generate a list of dates between start_date and end_date\n",
    "    date_list = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime('%m/%d/%Y'))\n",
    "        current_date += timedelta(days=1)\n",
    "    for num_date in date_list:\n",
    "        # This part here gets dictionary with string as key and numeric as value\n",
    "        date_object = datetime.strptime(num_date, '%m/%d/%Y')\n",
    "        day_of_week = date_object.strftime('%A')\n",
    "        string_with_dates[day_of_week] = num_date\n",
    "    # then we clean the dataframe\n",
    "    df = df[12:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reset_index().drop(columns=['index'])\n",
    "    df = df[1:]\n",
    "    need_columns = ['Region', 'Center',  \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    df = df[need_columns]\n",
    "    # we replace the string to numeric version\n",
    "    for date_string, date_numeric in string_with_dates.items():\n",
    "        df = df.rename(columns={date_string : date_numeric})\n",
    "    # then we unpivot the data \n",
    "    # REGION | CENTER | DATE | VALUE\n",
    "    df = df.melt(id_vars = ['Region', 'Center'] , var_name = \"Date\",  value_name='Count')\n",
    "    df = df.sort_values(by = 'Region')\n",
    "    # insert into the apprioate file\n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_PFD_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"PFD\", sheet_name)\n",
    " \n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "def PDOF(week, file):\n",
    "    sheet_name = 'PDOF'\n",
    "    string_with_dates = {}\n",
    "    day_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    try :\n",
    "        df = pd.read_excel(file , sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    # luckly the first column has start date and end date to convert string to numeric\n",
    "    date_range = df.columns[0]\n",
    "    index_string = date_range.index('between')\n",
    "    # the seperator is the between so lets get the dates\n",
    "    index_string =date_range[(index_string+len('between')):]\n",
    "    index_string = index_string.strip().replace(' ', '')\n",
    "    dates = index_string.split('and',1)\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime.strptime(dates[0], '%m/%d/%Y')\n",
    "    end_date = datetime.strptime(dates[1], '%m/%d/%Y')\n",
    "    # Generate a list of dates between start_date and end_date\n",
    "    date_list = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime('%m/%d/%Y'))\n",
    "        current_date += timedelta(days=1)\n",
    "    for num_date in date_list:\n",
    "        # This part here gets dictionary with string as key and numeric as value\n",
    "        date_object = datetime.strptime(num_date, '%m/%d/%Y')\n",
    "        day_of_week = date_object.strftime('%A')\n",
    "        string_with_dates[day_of_week] = num_date\n",
    "    # then we clean the dataframe\n",
    "    df = df[12:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reset_index().drop(columns=['index'])\n",
    "    df = df[1:]\n",
    "    need_columns = ['Region', 'Center',  \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    df = df[need_columns]\n",
    "    # we replace the string to numeric version\n",
    "    for date_string, date_numeric in string_with_dates.items():\n",
    "        df = df.rename(columns={date_string : date_numeric})\n",
    "    # then we unpivot the data \n",
    "    # REGION | CENTER | DATE | VALUE\n",
    "    df = df.melt(id_vars = ['Region', 'Center'] , var_name = \"Date\",  value_name='Count')\n",
    "    df = df.sort_values(by = 'Region')\n",
    "    # insert into the apprioate file\n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_PDOF_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"PDOF\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "def UA(week, file):\n",
    "    sheet_name = 'UA'\n",
    "    string_with_dates = {}\n",
    "    day_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    try :\n",
    "        df = pd.read_excel(file , sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    # luckly the first column has start date and end date to convert string to numeric\n",
    "    date_range = df.columns[0]\n",
    "    index_string = date_range.index('between')\n",
    "    # the seperator is the between so lets get the dates\n",
    "    index_string =date_range[(index_string+len('between')):]\n",
    "    index_string = index_string.strip().replace(' ', '')\n",
    "    dates = index_string.split('and',1)\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime.strptime(dates[0], '%m/%d/%Y')\n",
    "    end_date = datetime.strptime(dates[1], '%m/%d/%Y')\n",
    "    # Generate a list of dates between start_date and end_date\n",
    "    date_list = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime('%m/%d/%Y'))\n",
    "        current_date += timedelta(days=1)\n",
    "    for num_date in date_list:\n",
    "    # This part here gets dictionary with string as key and numeric as value\n",
    "        date_object = datetime.strptime(num_date, '%m/%d/%Y')\n",
    "        day_of_week = date_object.strftime('%A')\n",
    "        string_with_dates[day_of_week] = num_date\n",
    "    # then we clean the dataframe\n",
    "    df = df[12:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reset_index().drop(columns=['index'])\n",
    "    df = df[1:]\n",
    "    need_columns = ['Region', 'Center',  \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    df = df[need_columns]\n",
    "    # we replace the string to numeric version\n",
    "    for date_string, date_numeric in string_with_dates.items():\n",
    "        df = df.rename(columns={date_string : date_numeric})\n",
    "    # then we unpivot the data \n",
    "    # REGION | CENTER | DATE | VALUE\n",
    "    df = df.melt(id_vars = ['Region', 'Center'] , var_name = \"Date\",  value_name='Count')\n",
    "    df = df.sort_values(by = 'Region')\n",
    "    # insert into the apprioate file\n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_UA_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"UA\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def UA_separation(week, file):\n",
    "    sheet_name = \"UA Separation\"\n",
    "    try :\n",
    "        df = pd.read_excel(file , sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    df = df[25:]\n",
    "    path = \"1_8_Report\\PFD_PDOF_UA_Sep_01082025.xlsx\"\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.rename(columns={df.columns[2] : 'UA Sep Count'}).reset_index()\n",
    "    df = df[1:]\n",
    "    df = df.drop(columns='index')\n",
    "    wanted_cols = ['Region', 'Separation_Type', 'UA Sep Count']\n",
    "    df = df[wanted_cols]\n",
    "    # transpose first which will delelte the rows and then transpose\n",
    "    df = df.T.drop_duplicates().T\n",
    "    df['week'] = week\n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_UA_SEPARATION_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"UA_SEPARATION\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "# gather all the PFD files\n",
    "files_pfd = collect_files(folder = folder, pattern = 'pfd_pdof_ua')\n",
    "for week, file in files_pfd.items():\n",
    "    PFD(week, file)\n",
    "    PDOF(week, file)\n",
    "    UA(week, file)\n",
    "    UA_separation(week, file)\n",
    "# merge all the files\n",
    "merge(folder = \"PFD\")\n",
    "merge(folder = \"PDOF\")\n",
    "merge(folder = \"UA\")\n",
    "merge(folder = \"UA_SEPARATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fa947",
   "metadata": {},
   "source": [
    "# 5. Prospect Applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for cleaning and transforming the data\n",
    "def Prospect_applicant_online_prospect_submissions(week, file):\n",
    "    sheet_name = \"Online Prospects\"\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    df['week'] = week \n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_Prospect_Applicants_Online_Prospect_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"PROSPECT_APPLICANTS_ONLINE_PROSPECT\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Prospect_applicant_oasis(week, file):\n",
    "    sheet_name = \"Applicants\"\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    df['week'] = week \n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_Prospect_Applicants_OASIS_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"PROSPECT_APPLICANTS_OASIS\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "#  gather the prospect applicant  files\n",
    "files_pa = collect_files(folder=folder, pattern=\"prospects_applicants\")\n",
    "for week, file in files_pa.items():\n",
    "    Prospect_applicant_oasis(week, file)\n",
    "    Prospect_applicant_online_prospect_submissions(week,file)\n",
    "\n",
    "# merge\n",
    "merge('PROSPECT_APPLICANTS_OASIS')\n",
    "merge('PROSPECT_APPLICANTS_ONLINE_PROSPECT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2243faa",
   "metadata": {},
   "source": [
    "# 6. COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23283752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for cleaning and transforming the data\n",
    "def Covid(week, file):\n",
    "    sheet_name = \"Summary\"\n",
    "    try : \n",
    "        df = pd.read_excel (file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    df = df[4:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[0:13]\n",
    "    # want to include the total since Total is part of region and it has at least one value \n",
    "    df = df.dropna(thresh=2)\n",
    "    # loop\n",
    "    df= df.loc[:, df.columns.notna()]\n",
    "    df.columns = df.columns.str.replace(\"\\n\", \" \", regex=False)\n",
    "    df = df[1:]\n",
    "    df  =df.drop(columns = \"TOTALS\")\n",
    "    df['week'] = week \n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_COVID_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"COVID\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "#  gather the covid files\n",
    "files_covid = collect_files(folder= folder, pattern = \"sir_covid\")\n",
    "for week, file in files_covid.items():\n",
    "    Covid(week, file)\n",
    "# # merge all the files into one\n",
    "merge(\"COVID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541fa4f",
   "metadata": {},
   "source": [
    "# 7. Unpaid Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for cleaning and transforming the data\n",
    "def Unpaid_list(week, file):\n",
    "    sheet_name = \"Student List\"\n",
    "    try : \n",
    "        df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    df = df[0:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df['week'] = week \n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_Unpaid_List_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"UNPAID_LIST\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "def Unpaid_summary(week, file):\n",
    "    try : \n",
    "        sheet_name = \"Unpaid Summary by Pay Period\"\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {week}\")\n",
    "    df = df[3:]\n",
    "    df.columns  = df.iloc[0]\n",
    "    df = df.reset_index()\n",
    "    df = df[1:]\n",
    "    df = df.drop(columns='index')\n",
    "    df['week'] = week\n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_Unpaid_Summary_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"UNPAID_SUMMARY\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "# gather the unpaid student files\n",
    "files_unpaid  = collect_files(folder=folder, pattern=\"unpaid_students\")\n",
    "for week , file in files_unpaid.items():\n",
    "    Unpaid_summary(week, file)\n",
    "    Unpaid_list(week, file)\n",
    "merge(\"UNPAID_LIST\")\n",
    "merge(\"UNPAID_SUMMARY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b54412",
   "metadata": {},
   "source": [
    "# 8. Weekly OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for cleaning and transforming the data\n",
    "def OBS_report(week, file):\n",
    "    try :\n",
    "        sheet_name = \"OBS Report\"\n",
    "    except ValueError as e:\n",
    "            print(f\"An error occurred: {week}\")\n",
    "    df = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df = df.rename(columns = {df.columns[4]: \"ACTUAL OBS\"})\n",
    "    need_columns = ['State', 'Region', 'Center', 'PY 2024 Planned OBS', 'ACTUAL OBS']\n",
    "    df =df[need_columns]\n",
    "    df['week'] = week\n",
    "    start_date = week\n",
    "    sheet_name =  start_date.replace(\"/\", \"_\") + \"_OBS_report\" + \".xlsx\"\n",
    "    file_path = os.path.join(\"OBS\", sheet_name)\n",
    "    df.to_excel(file_path, index=False)\n",
    "# gather the weekly obs files\n",
    "files_OBS = collect_files(folder = folder, pattern = 'weekly_obs')\n",
    "for week, file in files_OBS.items():\n",
    "     OBS_report(week, file)\n",
    "# merge all \n",
    "merge(folder = \"OBS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7be1bf",
   "metadata": {},
   "source": [
    "# 9. All files in folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"update_weekly\"\n",
    "common_pattern = \"_DATA\"\n",
    "report_folder = \"ALL_REPORTS\"\n",
    "data_sources = []\n",
    "\n",
    "for secondary_dir in [d for d in os.listdir(folder) if d.isupper()]:\n",
    "    secondary_dir_path = os.path.join(folder, secondary_dir)\n",
    "    files_to_process = [f for f in os.listdir(secondary_dir_path) if common_pattern in f]\n",
    "\n",
    "    # Process each file that matches the pattern\n",
    "    for file in files_to_process:\n",
    "        file_path = os.path.join(secondary_dir_path, file)\n",
    "        df = pd.read_excel(file_path)\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        final_path = os.path.join(report_folder, file)\n",
    "        df.to_excel(final_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
